import torch
from torchmetrics.image.fid import FrechetInceptionDistance

def compute_fid(real_images, generated_images, device='cuda', feature_dim=2048):
    """
    Compute the Fr√©chet Inception Distance (FID) between two sets of images using torchmetrics.

    The FID is a measure of similarity between two datasets of images. It was shown to correlate well with human 
    judgement of visual quality and is most often used to evaluate the quality of images generated by GANs.

    Args:
        real_images (torch.Tensor): A tensor of real images. Shape should be (N, C, H, W) where N is the number of images,
                                    C is the number of channels, H is the height, and W is the width.
        generated_images (torch.Tensor): A tensor of generated images. Should have the same shape as real_images.
        device (str): The device to run the computation on. Default is 'cuda'.
        feature_dim (int): The dimension of the Inception features to use. Default is 2048.

    Returns:
        float: The computed FID score.

    Raises:
        ValueError: If the input tensors have incorrect shapes or types.

    Note:
        This function uses the torchmetrics library implementation of FID, which internally uses a pre-trained 
        Inception v3 model. The images should be in the range [0, 255] and of type uint8 before being passed to this function.
    """
    if not isinstance(real_images, torch.Tensor) or not isinstance(generated_images, torch.Tensor):
        raise ValueError("Input images must be PyTorch tensors")
    
    if real_images.shape != generated_images.shape:
        raise ValueError("Real and generated image tensors must have the same shape")

    # Initialize the FID metric
    fid = FrechetInceptionDistance(feature=feature_dim).to(device)

    # Update the FID metric with real and generated images
    fid.update(real_images, real=True)
    fid.update(generated_images, real=False)

    # Compute the FID score
    fid_score = fid.compute().item()

    return fid_score

